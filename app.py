# app.py

import streamlit as st
import openai
import pytesseract
from PIL import Image
import os
import io

 import support_arabic_text

# ØªÙØ¹ÙŠÙ„ Ø¯Ø¹Ù… Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
support_arabic_text(all=True)

# ğŸŸ¢ Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø© Ø¨Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
def get_ocr_from_camera():
 #st.write("Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø© Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ")
 image_data = st.camera_input(":Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø© Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ")

# ğŸ”µ Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© ÙˆØªØ­Ù„ÙŠÙ„Ù‡Ø§ Ù„Ø§Ø­Ù‚Ù‹Ø§
 if image_data is not None:
    # Ù†Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© ÙƒÙ…Ù„Ù Ù…Ø­Ù„ÙŠ
    with open("saved_image.jpg", "wb") as f:
        f.write(image_data.getbuffer())
    st.success("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ù†Ø¬Ø§Ø­ Ø¨Ø§Ø³Ù… saved_image.jpg")
    
    # st.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙˆØ±Ø© Ù…Ø­ÙÙˆØ¸Ø© Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†.")
 return image_data
    
#Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„Ù…Ù„ØµÙ‚ Ø§Ù„Ù…Ù†ØªØ¬
def upload_image_ocr_from_folder():
 uploaded_file = st.file_uploader("ğŸ“¸: Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© ", type=["png", "jpg", "jpeg"])

 return uploaded_file

    #Ø­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ù†Øµ
def extract_text_from_image(saved_image):
    with st.spinner("ğŸ§  Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©..."):
       # image = Image.open(saved_image)
        ingredients_text = pytesseract.image_to_string(saved_image, lang="eng+ara+sve")
        st.text_area("ğŸ“„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©:", value=ingredients_text , height=200)
    return ingredients_text
    
#  ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT-4
def analyze_ingredients_with_gpt(ingredients_text):
    prompt = f"""
    Ù‡Ù„ ØªØ­ØªÙˆÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¹Ù„Ù‰ Ø£ÙŠ Ù…ÙƒÙˆÙ† Ù…Ø´ØªÙ‚ Ù…Ù† Ø§Ù„Ø­Ø´Ø±Ø§ØªØŸ
    Ø¥Ø°Ø§ ÙƒØ§Ù† Ù†Ø¹Ù…ØŒ Ø§Ø°ÙƒØ± Ø§Ù„Ù…ÙƒÙˆÙ† ÙˆÙˆØ¶Ø­ Ù…ØµØ¯Ø±Ù‡. Ø¥Ø°Ø§ Ù„Ø§ØŒ Ù‚Ù„ Ø£Ù†Ù‡Ø§ Ø®Ø§Ù„ÙŠØ©.
    Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª:
    {ingredients_text}
    """
    try:
        response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )
        result= response['choices'][0]['message']['content']
        st.success("âœ… Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„:")
        st.markdown(result)
    except Exception as e:
         st.error(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ GPT-4: {e}")
    
# OpenAI API key
openai.api_key = os.getenv("OPENAI_API_KEY") or "Ø¶Ø¹_Ù…ÙØªØ§Ø­Ùƒ_Ù‡Ù†Ø§"

# Ø¥Ø°Ø§ ÙƒÙ†Øª Ø¹Ù„Ù‰ Windows:
#pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

st.set_page_config(page_title="ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„ØºØ°Ø§Ø¦ÙŠØ©", page_icon="ğŸ", layout="centered")

st.title("ğŸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„ØºØ°Ø§Ø¦ÙŠØ©")
st.write("ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø´ØªÙ‚Ø§Øª Ù…Ù† Ø§Ù„Ø­Ø´Ø±Ø§Øª.")

manual_input = st.text_area("Ø£Ùˆ Ø£Ø¯Ø®Ù„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª ÙŠØ¯ÙˆÙŠÙ‹Ø§")


# ğŸŸ¢ Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø© Ø¨Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
saved_image = get_ocr_from_camera()
    
#Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„Ù…Ù„ØµÙ‚ Ø§Ù„Ù…Ù†ØªØ¬
saved_image = upload_image_ocr_from_folder()
st.write("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„Ù…Ù„ØµÙ‚ Ø§Ù„Ù…Ù†ØªØ¬ ÙˆØ³Ù†Ù‚ÙˆÙ… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ù„Ù…Ø¹Ø±ÙØ© Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø´ØªÙ‚Ø§Øª Ù…Ù† Ø§Ù„Ø­Ø´Ø±Ø§Øª.")

if saved_image:
 st.image(saved_image, caption="ğŸ“· Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ØªÙŠ ØªÙ… Ø±ÙØ¹Ù‡Ø§", use_column_width=True)
else:
 st.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙˆØ±Ø© Ù…Ø­ÙÙˆØ¸Ø© Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†.")

  
 
if saved_image:
        ingredients_text = extract_text_from_image(saved_image)
else:
        ingredients_text = manual_input
        
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT-4
if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ"):
   
       st.spinner("ğŸ¤– ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT-4...")
    
       analyze_ingredients_with_gpt(ingredients_text)
       
