# app.py

import easyocr
import streamlit as st
import openai
import pytesseract
from PIL import Image,ImageDraw
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sqlalchemy.orm import declarative_base, sessionmaker
import os
import uuid
import io
from models import OCRImage, create_new_dbsqlite###
from arabic_support import support_arabic_text
#pip install nest_asyncio
#Ù„Ù„Ø³Ù…Ø§Ø­ Ø¨ØªØ´ØºÙŠÙ„ Ø§Ù„Ø­Ù„Ù‚Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©
#import nest_asyncio
#nest_asyncio.apply()

#Ù‡Ø°Ø§ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ ÙŠØ³Ø§Ø¹Ø¯ Ø¹Ù„Ù‰ ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ù…ØªØ¹Ù„Ù‚ Ø¨Ù€ torch.classes.
#Ø¯Ø¹Ù… ÙÙ„Ø§ØªØ±: "Ù†Ø¨Ø§ØªÙŠ ÙÙ‚Ø·" â€“ "Ø®Ø§Ù„Ù Ù…Ù† Ø§Ù„Ø­Ø´Ø±Ø§Øª" â€“ "Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù…Ø³Ù„Ù…ÙŠÙ†".


import torch
torch.classes.__path__ = []


# ÙˆØ¸ÙŠÙØ© Ù„Ø­Ø³Ø§Ø¨ ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù†ØµÙˆØµ
def calculate_similarity(text1, text2):
    vectorizer = TfidfVectorizer().fit_transform([text1, text2])
    similarity = cosine_similarity(vectorizer[0:1], vectorizer[1:2])
    return similarity[0][0]
# ğŸŸ¢ Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø© Ø¨Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
def get_ocr_from_camera():
    # ØªÙ‡ÙŠØ¦Ø© EasyOCR
    reader = easyocr.Reader(['sv', 'da'])  # Ø¯Ø¹Ù… Ø§Ù„Ø³ÙˆÙŠØ¯ÙŠØ© ÙˆØ§Ù„Ø¯Ù†Ù…Ø§Ø±ÙƒÙŠØ©

    img_file = st.camera_input("ğŸ“¸ Ø§Ù„ØªÙ‚Ø· ØµÙˆØ±Ø©")

    if img_file is not None:
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø© ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ NumPy array
        img = Image.open(img_file)
        img_np = np.array(img.resize((800, 600)))  # ØªØµØºÙŠØ± Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø³Ø±Ø¹Ø©

        with st.spinner("ğŸ” Ø¬Ø§Ø±Ù ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©..."):
            # ØªØ´ØºÙŠÙ„ OCR
            results = reader.readtext(
                img_np,
                batch_size=4,
                allowlist='0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ',
                paragraph=True
            )

        # Ø±Ø³Ù… Ø§Ù„Ù…Ø³ØªØ·ÙŠÙ„Ø§Øª Ø­ÙˆÙ„ Ø§Ù„Ù†ØµÙˆØµ
            draw = ImageDraw.Draw(img)
        for (bbox, text, confidence) in results:

            top_left = tuple(bbox[0])
            bottom_right = tuple(bbox[2])
            draw.rectangle([top_left, bottom_right], outline="red", width=5)

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ ÙÙ‚Ø·
            extracted_texts = [text for (_, text, _) in results]
            combined_text = "\n".join(extracted_texts)

        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            st.subheader("ğŸ“ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…ÙƒØªØ´ÙØ©:")
        for text in extracted_texts:
            st.write(f"- {text}")

            st.image(img, caption="ğŸ“· Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ Ø§Ù„ØªØ­Ø¯ÙŠØ¯Ø§Øª", use_container_width=True)
            st.text_area("ğŸ“„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¬Ù…Ø¹:", value=combined_text, height=200)

        # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        return {
            'image': img,
            'text_results': combined_text
        }

    # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø©
    return None

    # st.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙˆØ±Ø© Ù…Ø­ÙÙˆØ¸Ø© Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†.")
    
#Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„Ù…Ù„ØµÙ‚ Ø§Ù„Ù…Ù†ØªØ¬
def upload_image_ocr_from_folder():
    uploaded_file = st.file_uploader("ğŸ“¸: Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© ", type=["png", "jpg", "jpeg"])
    if uploaded_file is not None:
        try:
            image = Image.open(uploaded_file)
            st.image(image, caption="ğŸ“· Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ØªÙŠ ØªÙ… Ø±ÙØ¹Ù‡Ø§", use_container_width=True)
            return image
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ÙØªØ­ Ø§Ù„ØµÙˆØ±Ø©: {e}")
            return None
    else:
        st.warning("Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø£ÙŠ Ù…Ù„Ù.")
        return None
        #####
 def extract_text_from_image(saved_image):     

    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù‚Ø§Ø±Ø¦ (ÙŠÙÙØ¶Ù„ Ø£Ù† ØªÙƒÙˆÙ† Ø®Ø§Ø±Ø¬ Ø§Ù„Ø¯Ø§Ù„Ø© Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡)
    reader = easyocr.Reader(['sv', 'da'])
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
    img_np = np.array(saved_image)
    
    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†Øµ Ù…Ø¹ ØªÙØ¹ÙŠÙ„ Ø®ÙŠØ§Ø± Ø§Ù„ØªÙØ§ØµÙŠÙ„
    results = reader.readtext(img_np, detail=1)  # detail=1 Ù„Ø¥Ø±Ø¬Ø§Ø¹ ÙƒÙ„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
    
    extracted_texts = []
    st.subheader("ğŸ“ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…ÙƒØªØ´ÙØ©:")
    
    for item in results:
        try:
            # Ø·Ø±ÙŠÙ‚Ø© Ø¢Ù…Ù†Ø© Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø¨Ù†ÙŠØ§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
            if len(item) == 3:  # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ bbox, text, confidence
                bbox, text, confidence = item
            elif len(item) == 2:  # Ø¨Ø¹Ø¶ Ø§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª ØªÙØ±Ø¬Ø¹ (text, bbox)
                text, bbox = item
                confidence = None
            else:
                continue
                
            st.write(f"- {text} (Ø§Ù„Ø¯Ù‚Ø©: {confidence:.2f})" if confidence else f"- {text}")
            extracted_texts.append(text)
            
        except Exception as e:
            st.warning(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ù†ØµØ±: {e}")
            continue
    
    combined_text = "\n".join(extracted_texts)
    st.text_area("ğŸ“„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬:", value=combined_text, height=200)
    
    return  combined_text
           
    #Ø­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ù†Øµ

    
#  ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT-4
#def analyze_ingredients_with_gpt(ingredients_text):

    
    # Ø¯Ø§Ù„Ø© Ù„ØªØ¨Ø¯ÙŠÙ„ Ø­Ø§Ù„Ø© Ø§Ù„Ø¹Ø±Ø¶
#def toggle_message_input():
 #   st.session_state.show_message_input = not st.session_state.show_message_input

def toggle_message_camera():
    st.session_state.show_message_camera = not st.session_state.show_message_camera

def toggle_message_upload():
    st.session_state.show_message_upload = not st.session_state.show_message_upload


# OpenAI API key
openai.api_key = os.getenv("OPENAI_API_KEY") or "Ø¶Ø¹_Ù…ÙØªØ§Ø­Ùƒ_Ù‡Ù†Ø§"

# Ø¥Ø°Ø§ ÙƒÙ†Øª Ø¹Ù„Ù‰ Windows:
#pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"


# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (ÙÙ‚Ø· Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø©)
#session = create_new_dbsqlite('sqlite:///mydatabase.db')

st.set_page_config(page_title="ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„ØºØ°Ø§Ø¦ÙŠØ©", page_icon="ğŸ", layout="centered")

# ØªÙØ¹ÙŠÙ„ Ø¯Ø¹Ù… Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
support_arabic_text(all=True)

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…ÙØªØ§Ø­ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©ØŒ ÙˆØ¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§ØŒ ÙŠØªÙ… ØªÙ‡ÙŠØ¦ØªÙ‡
#if 'show_message_input' not in st.session_state:
 #   st.session_state.show_message_input = True
if 'show_message_camera' not in st.session_state:
    st.session_state.show_message_camera = False
if 'show_message_upload' not in st.session_state:
    st.session_state.show_message_upload = True
# Ø¥Ù†Ø´Ø§Ø¡ Ø«Ù„Ø§Ø«Ø© Ø£Ø¹Ù…Ø¯Ø© Ø¨Ù†Ø³Ø¨Ø© Ø¹Ø±Ø¶ Ù…ØªØ³Ø§ÙˆÙŠØ©
col1, col2, col3 = st.columns([1, 4, 1])
# Default values


with col2:
 st.title("ğŸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„ØºØ°Ø§Ø¦ÙŠØ©")

st.write("ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø´ØªÙ‚Ø§Øª Ù…Ù† Ø§Ù„Ø­Ø´Ø±Ø§Øª.")


    # Ø²Ø± Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
#st.button("âœï¸ Ø£Ø¯Ø®Ù„ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª", on_click=toggle_message_input, use_container_width=True)
st.button("ğŸ§  Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø©", on_click=toggle_message_upload, use_container_width=True)
st.button("ğŸ“¸ Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø©", on_click=toggle_message_camera, use_container_width=True)
# Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…

 #Ø¹Ø±Ø¶ Ø£Ùˆ Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©
#if st.session_state.show_message_input:
 #ingredients_text = st.text_area("âœï¸ Ø£Ø¯Ø®Ù„ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª (ÙŠÙ…ÙƒÙ†Ùƒ Ù†Ø³Ø®Ù‡Ø§ Ù…Ù† Ø§Ù„Ù…Ù„ØµÙ‚):", height=200)
 #st.session_state.show_message_camera = False
 #st.session_state.show_message_upload = False
#else:
saved_image =""
result=""
# ğŸŸ¢ Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø© Ø¨Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
if st.session_state.show_message_upload:
    saved_image = upload_image_ocr_from_folder()
    st.session_state.show_message_camera = False

elif st.session_state.show_message_camera:
     result = get_ocr_from_camera()
    
     if  result:
       st.write("âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ù†Ø¬Ø§Ø­!")
     
       st.session_state.show_message_upload = False

st.write("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„Ù…Ù„ØµÙ‚ Ø§Ù„Ù…Ù†ØªØ¬ ÙˆØ³Ù†Ù‚ÙˆÙ… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ù„Ù…Ø¹Ø±ÙØ© Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø´ØªÙ‚Ø§Øª Ù…Ù† Ø§Ù„Ø­Ø´Ø±Ø§Øª.")



    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT-4
extracted_text=""
if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ", use_container_width=True):
    if saved_image:
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ..."):
             extracted_text = extract_text_from_image(saved_image)

        if not extracted_text.strip():
               st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Øµ Ù‚Ø§Ø¨Ù„ Ù„Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©.")
    
