# app.py

import easyocr
import streamlit as st
import openai
import pytesseract
from PIL import Image,ImageDraw
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sqlalchemy.orm import declarative_base, sessionmaker
import os
import uuid
import io
from models import OCRImage, create_new_dbsqlite###
from arabic_support import support_arabic_text
#pip install nest_asyncio
#Ù„Ù„Ø³Ù…Ø§Ø­ Ø¨ØªØ´ØºÙŠÙ„ Ø§Ù„Ø­Ù„Ù‚Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©
#import nest_asyncio
#nest_asyncio.apply()

#Ù‡Ø°Ø§ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ ÙŠØ³Ø§Ø¹Ø¯ Ø¹Ù„Ù‰ ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ù…ØªØ¹Ù„Ù‚ Ø¨Ù€ torch.classes.
#Ø¯Ø¹Ù… ÙÙ„Ø§ØªØ±: "Ù†Ø¨Ø§ØªÙŠ ÙÙ‚Ø·" â€“ "Ø®Ø§Ù„Ù Ù…Ù† Ø§Ù„Ø­Ø´Ø±Ø§Øª" â€“ "Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù…Ø³Ù„Ù…ÙŠÙ†".


import torch
torch.classes.__path__ = []


# ÙˆØ¸ÙŠÙØ© Ù„Ø­Ø³Ø§Ø¨ ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù†ØµÙˆØµ
def calculate_similarity(text1, text2):
    vectorizer = TfidfVectorizer().fit_transform([text1, text2])
    similarity = cosine_similarity(vectorizer[0:1], vectorizer[1:2])
    return similarity[0][0]
# ğŸŸ¢ Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø© Ø¨Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
def get_ocr_from_camera():
    img_file = st.camera_input("Ø§Ù„ØªÙ‚Ø· ØµÙˆØ±Ø©")

    if img_file is not None:
        img = Image.open(img_file).convert("RGB")
        img_np = np.array(img)

        reader = easyocr.Reader(['ar', 'en'])
        with st.spinner("ğŸ” Ø¬Ø§Ø±Ù ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©..."):
            results = reader.readtext(img_np)

        draw = ImageDraw.Draw(img)
        for (bbox, text, confidence) in results:
            top_left = tuple(bbox[0])
            bottom_right = tuple(bbox[2])
            draw.rectangle([top_left, bottom_right], outline="red", width=3)

        st.image(img, caption="ğŸ“„ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ Ø§Ù„Ù…Ø³ØªØ·ÙŠÙ„Ø§Øª Ø­ÙˆÙ„ Ø§Ù„Ù†ØµÙˆØµ", use_container_width=True)

        return img

    # st.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙˆØ±Ø© Ù…Ø­ÙÙˆØ¸Ø© Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†.")
    
#Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„Ù…Ù„ØµÙ‚ Ø§Ù„Ù…Ù†ØªØ¬
def upload_image_ocr_from_folder():
    uploaded_file = st.file_uploader("ğŸ“¸: Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© ", type=["png", "jpg", "jpeg"])
    if uploaded_file is not None:
        try:
            image = Image.open(uploaded_file)
            st.image(image, caption="ğŸ“· Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ØªÙŠ ØªÙ… Ø±ÙØ¹Ù‡Ø§", use_container_width=True)
            return image
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ÙØªØ­ Ø§Ù„ØµÙˆØ±Ø©: {e}")
            return None
    else:
        st.warning("Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø£ÙŠ Ù…Ù„Ù.")
        return None
        
    #Ø­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ù†Øµ
def extract_text_from_image1(saved_image) -> str:
  #  """
  #  ØªØ³ØªØ®Ø±Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø³Ø±Ø¹Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… EasyOCR ÙˆØªØ¹ÙŠØ¯Ù‡ ÙƒØ³Ù„Ø³Ù„Ø© Ù†ØµÙŠØ©.
    
   # Args:
    #    saved_image: ØµÙˆØ±Ø© Ù…Ø¯Ø®Ù„Ø© (PIL.Image Ø£Ùˆ numpy array).
    
  #  Returns:
   #     str: Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ø¬Ù…Ø¹ ÙÙŠ Ø³Ù„Ø³Ù„Ø© ÙˆØ§Ø­Ø¯Ø©.
   # """
    try:
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ numpy array Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©
        img_np = np.array(saved_image)
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø© Ù…Ø¹ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ÙØ­Ø³Ù†Ø©
        results = reader.readtext(
            img_np,
            batch_size=4,  # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯ÙÙØ¹Ø§Øª Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
            paragraph=True,  # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ÙÙ‚Ø±Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§
            decoder='beamsearch',  # Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø£Ø³Ø±Ø¹ Ù„Ù„ÙÙƒ
            detail=0  # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†Øµ ÙÙ‚Ø· (Ø¨Ø¯Ø¡Ù‹Ø§ Ù…Ù† Ø¥ØµØ¯Ø§Ø± EasyOCR 1.7)
        )
        
        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØµÙˆØµ (Ø¥Ø°Ø§ ÙƒØ§Ù† detail=0ØŒ ØªÙƒÙˆÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø¨Ø§Ø´Ø±Ø© ÙƒÙ‚Ø§Ø¦Ù…Ø© Ù†ØµÙˆØµ)
        results = reader.readtext(img_np, allowlist='0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')
        combined_text = "\n".join(results)
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Streamlit (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        if st:
            st.subheader("ğŸ“ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…ÙƒØªØ´ÙØ©:")
            st.text_area("ğŸ“„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©:", value=combined_text, height=200)
        
        return combined_text
    
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©: {e}")
        return ""
    
#  ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT-4
#def analyze_ingredients_with_gpt(ingredients_text):

    
    # Ø¯Ø§Ù„Ø© Ù„ØªØ¨Ø¯ÙŠÙ„ Ø­Ø§Ù„Ø© Ø§Ù„Ø¹Ø±Ø¶
#def toggle_message_input():
 #   st.session_state.show_message_input = not st.session_state.show_message_input

def toggle_message_camera():
    st.session_state.show_message_camera = not st.session_state.show_message_camera

def toggle_message_upload():
    st.session_state.show_message_upload = not st.session_state.show_message_upload


# OpenAI API key
openai.api_key = os.getenv("OPENAI_API_KEY") or "Ø¶Ø¹_Ù…ÙØªØ§Ø­Ùƒ_Ù‡Ù†Ø§"

# Ø¥Ø°Ø§ ÙƒÙ†Øª Ø¹Ù„Ù‰ Windows:
#pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"


# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (ÙÙ‚Ø· Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø©)
#session = create_new_dbsqlite('sqlite:///mydatabase.db')

st.set_page_config(page_title="ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„ØºØ°Ø§Ø¦ÙŠØ©", page_icon="ğŸ", layout="centered")

# ØªÙØ¹ÙŠÙ„ Ø¯Ø¹Ù… Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
support_arabic_text(all=True)
# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…ÙØªØ§Ø­ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©ØŒ ÙˆØ¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§ØŒ ÙŠØªÙ… ØªÙ‡ÙŠØ¦ØªÙ‡
#if 'show_message_input' not in st.session_state:
 #   st.session_state.show_message_input = True
if 'show_message_camera' not in st.session_state:
    st.session_state.show_message_camera = False
if 'show_message_upload' not in st.session_state:
    st.session_state.show_message_upload = True
# Ø¥Ù†Ø´Ø§Ø¡ Ø«Ù„Ø§Ø«Ø© Ø£Ø¹Ù…Ø¯Ø© Ø¨Ù†Ø³Ø¨Ø© Ø¹Ø±Ø¶ Ù…ØªØ³Ø§ÙˆÙŠØ©
col1, col2, col3 = st.columns([1, 4, 1])
# Default values


with col2:
 st.title("ğŸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„ØºØ°Ø§Ø¦ÙŠØ©")

st.write("ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø´ØªÙ‚Ø§Øª Ù…Ù† Ø§Ù„Ø­Ø´Ø±Ø§Øª.")


    # Ø²Ø± Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
#st.button("âœï¸ Ø£Ø¯Ø®Ù„ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª", on_click=toggle_message_input, use_container_width=True)
st.button("ğŸ§  Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø©", on_click=toggle_message_upload, use_container_width=True)
st.button("ğŸ“¸ Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø©", on_click=toggle_message_camera, use_container_width=True)
# Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…

 #Ø¹Ø±Ø¶ Ø£Ùˆ Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©
#if st.session_state.show_message_input:
 #ingredients_text = st.text_area("âœï¸ Ø£Ø¯Ø®Ù„ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª (ÙŠÙ…ÙƒÙ†Ùƒ Ù†Ø³Ø®Ù‡Ø§ Ù…Ù† Ø§Ù„Ù…Ù„ØµÙ‚):", height=200)
 #st.session_state.show_message_camera = False
 #st.session_state.show_message_upload = False
#else:

# ğŸŸ¢ Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø© Ø¨Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
if st.session_state.show_message_upload:
    saved_image = upload_image_ocr_from_folder()
    st.session_state.show_message_camera = False

elif st.session_state.show_message_camera:
    saved_image = get_ocr_from_camera()
    st.session_state.show_message_upload = False

st.write("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„Ù…Ù„ØµÙ‚ Ø§Ù„Ù…Ù†ØªØ¬ ÙˆØ³Ù†Ù‚ÙˆÙ… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ù„Ù…Ø¹Ø±ÙØ© Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø´ØªÙ‚Ø§Øª Ù…Ù† Ø§Ù„Ø­Ø´Ø±Ø§Øª.")



    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT-4

if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ", use_container_width=True):
    if saved_image:
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ..."):
            extracted_text = extract_text_from_image(saved_image)

        if not extracted_text.strip():
            st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Øµ Ù‚Ø§Ø¨Ù„ Ù„Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©.")
    
